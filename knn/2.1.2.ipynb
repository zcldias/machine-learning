{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#knn 2.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#k-近邻（k-Nearest Neighbour，简称KNN），常用于有监督学习。\n",
    "\n",
    "#KNN的工作原理很简单：存在一个训练样本集合A，在给定测试样本b时，基于某种距离度量，找出训练集A中与测试样本b最靠近的k个训练样本（通常k≤20且为整数），之后，基于这k个训练样本的信息来预测种类或值。\n",
    "\n",
    "#其中，在分类问题中，KNN用来预测种类。一般使用“投票法”，选择这k个样本中出现最多的类别来作为测试样本的类别。\n",
    "\n",
    "#在回归问题中，KNN预测一个值。使用“平均法”，将k个样本的实值输出的平均值作为测试样本的输出。一般情况下，距离度量选择欧式距离\n",
    "\n",
    "#KNN算法作为一种较简单的算法，它的不足之处在于：\n",
    "\n",
    "#(1)没有明显的训练过程，它是“懒惰学习”的典型代表，它在训练阶段所做的仅仅是将样本保存起来，如果训练集很大，必须使用大量的存储空间，训练时间开销为零；\n",
    "\n",
    "#(2)必须对数据集中每个数据计算距离值，实际中可能非常耗时。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#为了提高KNN搜索的速度，可以利用特殊的数据存储形式来减少计算距离的次数。kd树就是一种以二叉树的形式存储数据的方法。\n",
    "#kd树就是对k维空间的一个划分。构造kd树相当于不断用垂直于坐标轴的超平面将k维空间切分，构成一系列k维超矩阵区域。\n",
    "#kd树的每一个节点对应一个超矩阵区域。（想要深入了解的同学可以参看李航老师的《统计机器学习》P41页）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import operator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def createDataSet ():\n",
    "    group = np.array([[1.0,1.1],[1.0,1.0],[0,0],[0,0.1]])\n",
    "    labels = [\"A\",\"A\",\"B\",\"B\"]\n",
    "    return group,labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1.   1.1]\n",
      " [ 1.   1. ]\n",
      " [ 0.   0. ]\n",
      " [ 0.   0.1]]\n",
      "['A', 'A', 'B', 'B']\n"
     ]
    }
   ],
   "source": [
    "group,labels = createDataSet ()\n",
    "print(group)\n",
    "print(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def classify0(inX,dataSet,labels,k):\n",
    "    dataSetSize = dataSet.shape[0]\n",
    "    #返回dataSet的行数\n",
    "    diffMat = np.tile(inX,(dataSetSize,1))-dataSet\n",
    "    print(\"diffMat:\")\n",
    "    print(diffMat)\n",
    "    # tile（）函数实现矩阵重复，\n",
    "    # 在列方向重复inX共1次，在行方向重复inX共dataSetSize次\n",
    "    #可以使用help（tile）察看用法\n",
    "    sqDiffMat =  diffMat**2\n",
    "    sqDistances = sqDiffMat.sum(axis=1)\n",
    "    #sum()为求和，参数axis=1为行方向求和，axis=0为列方向求和\n",
    "    distances = sqDistances**0.5\n",
    "    sortedDistIndicies = distances.argsort()\n",
    "    #distances.argsort()将distances中的元素按照从小到大排序，并且返回所引值\n",
    "    #注意，sortedDistIndicies中存放的是返回的所引值，不是distances中的元素\n",
    "    \n",
    "    \n",
    "    \n",
    "    classCount = {}\n",
    "    #创建一个字典dict\n",
    "    for i in range(k):\n",
    "        voteIlabel = labels[sortedDistIndicies[i]]\n",
    "        #返回距离排名第i的标签\n",
    "        classCount[voteIlabel] = classCount.get(voteIlabel,0)+1\n",
    "        #dict.get(key,default=None),返回字典中指定键key的值，如果键 key 不在字典中则返回default值\n",
    "        #上式计算了类别的数目\n",
    "    sortedClassCount = sorted(classCount.items(),key=operator.itemgetter(1),reverse=True)\n",
    "    # 将classCount中的值进行排序\n",
    "    # sorted(iterable,cmp=None,key=None,reverse=False)\n",
    "    # terable：是可迭代类型;\n",
    "    # cmp：用于比较的函数，比较什么由key决定;\n",
    "    # key：用列表元素的某个属性或函数进行作为关键字，有默认值，迭代集合中的一项;\n",
    "    # key=operator.itemgetter(1)根据字典的值进行排序，key=operator.itemgetter(0)根据字典的键进行排序\n",
    "    # reverse：排序规则. reverse = True  降序 或者 reverse = False 升序，有默认值。\n",
    "    # 返回值：是一个经过排序的可迭代类型，与iterable一样。\n",
    "    return sortedClassCount[0][0]\n",
    "    # 返回分类的类别\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "diffMat:\n",
      "[[-1.  -1.1]\n",
      " [-1.  -1. ]\n",
      " [ 0.   0. ]\n",
      " [ 0.  -0.1]]\n",
      "B\n"
     ]
    }
   ],
   "source": [
    "# test\n",
    "feilei = classify0([0,0],group,labels,3)\n",
    "print(feilei)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111)\n",
    "# fig, axes = plt.subplots(m, n)完成上述两步操作\n",
    "ax.scat"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
